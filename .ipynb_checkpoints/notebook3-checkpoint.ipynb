{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2477ac89-766f-4de3-b870-ac2684609732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSOA11CD', 'IMD19', 'lat', 'lon']\n",
      "Total images found: 36\n",
      "                      image_path       lsoa  imd_score\n",
      "0    data/images/E01030408_0.jpg  E01030408    32736.0\n",
      "1    data/images/E01002082_0.jpg  E01002082      546.0\n",
      "2   data/images/E01030542_90.jpg  E01030542    32796.0\n",
      "3  data/images/E01030353_180.jpg  E01030353    32727.0\n",
      "4  data/images/E01030542_180.jpg  E01030542    32796.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load LSOA data\n",
    "lsoas = pd.read_csv('data/test_lsoas.csv')\n",
    "print(lsoas.columns.tolist())\n",
    "\n",
    "# Build list of all images with their IMD scores\n",
    "image_dir = 'data/images/'\n",
    "records = []\n",
    "\n",
    "for fname in os.listdir(image_dir):\n",
    "    if not fname.endswith('.jpg') or fname == 'test_image.jpg':\n",
    "        continue\n",
    "    lsoa_code = fname.rsplit('_', 1)[0]\n",
    "    match = lsoas[lsoas['LSOA11CD'] == lsoa_code]\n",
    "    if not match.empty:\n",
    "        score = match['IMD19'].values[0]\n",
    "        records.append({\n",
    "            'image_path': os.path.join(image_dir, fname),\n",
    "            'lsoa': lsoa_code,\n",
    "            'imd_score': float(score)\n",
    "        })\n",
    "\n",
    "records_df = pd.DataFrame(records)\n",
    "print(f\"Total images found: {len(records_df)}\")\n",
    "print(records_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd90e5e-8efc-41fe-838d-96cde6a48011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score range: 546 to 32796\n",
      "         lsoa  imd_score  imd_norm\n",
      "0   E01030408    32736.0  0.998140\n",
      "1   E01002082      546.0  0.000000\n",
      "2   E01030542    32796.0  1.000000\n",
      "3   E01030353    32727.0  0.997860\n",
      "6   E01000601     1192.0  0.020031\n",
      "7   E01030518    32789.0  0.999783\n",
      "8   E01001178     1096.0  0.017054\n",
      "11  E01023839    32742.0  0.998326\n",
      "14  E01002857     1012.0  0.014450\n",
      "\n",
      "Train: 28 | Val: 8\n"
     ]
    }
   ],
   "source": [
    "# Normalise IMD score to 0-1\n",
    "score_min = records_df['imd_score'].min()\n",
    "score_max = records_df['imd_score'].max()\n",
    "records_df['imd_norm'] = (records_df['imd_score'] - score_min) / (score_max - score_min)\n",
    "\n",
    "print(f\"Score range: {score_min:.0f} to {score_max:.0f}\")\n",
    "print(records_df[['lsoa', 'imd_score', 'imd_norm']].drop_duplicates('lsoa'))\n",
    "\n",
    "# Split 80/20\n",
    "train_df, val_df = train_test_split(records_df, test_size=0.2, random_state=42)\n",
    "print(f\"\\nTrain: {len(train_df)} | Val: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3b6605-e228-468a-97f1-4cd5c358f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 4\n",
      "Val batches: 1\n"
     ]
    }
   ],
   "source": [
    "class StreetViewDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['image_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(row['imd_norm'], dtype=torch.float32)\n",
    "        return image, label\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = StreetViewDataset(train_df, transform=train_transform)\n",
    "val_dataset = StreetViewDataset(val_df, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e57a1d-7f1b-430e-95d7-be75e6d9a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/25 | Train: 0.2164 | Val: 0.2004 | R²: 0.121\n",
      "  → Best model saved (epoch 1)\n",
      "Epoch  2/25 | Train: 0.0382 | Val: 0.1713 | R²: 0.249\n",
      "  → Best model saved (epoch 2)\n",
      "Epoch  3/25 | Train: 0.0349 | Val: 0.1340 | R²: 0.412\n",
      "  → Best model saved (epoch 3)\n",
      "Epoch  4/25 | Train: 0.0058 | Val: 0.0973 | R²: 0.573\n",
      "  → Best model saved (epoch 4)\n",
      "Epoch  5/25 | Train: 0.0190 | Val: 0.0803 | R²: 0.648\n",
      "  → Best model saved (epoch 5)\n",
      "Epoch  6/25 | Train: 0.0045 | Val: 0.0425 | R²: 0.814\n",
      "  → Best model saved (epoch 6)\n",
      "Epoch  7/25 | Train: 0.0145 | Val: 0.0296 | R²: 0.870\n",
      "  → Best model saved (epoch 7)\n",
      "Epoch  8/25 | Train: 0.0470 | Val: 0.0132 | R²: 0.942\n",
      "  → Best model saved (epoch 8)\n",
      "Epoch  9/25 | Train: 0.0009 | Val: 0.0156 | R²: 0.931\n",
      "Epoch 10/25 | Train: 0.0069 | Val: 0.0219 | R²: 0.904\n",
      "Epoch 11/25 | Train: 0.0085 | Val: 0.0237 | R²: 0.896\n",
      "Epoch 12/25 | Train: 0.0373 | Val: 0.0161 | R²: 0.929\n",
      "Epoch 13/25 | Train: 0.0007 | Val: 0.0170 | R²: 0.925\n",
      "Epoch 14/25 | Train: 0.0004 | Val: 0.0180 | R²: 0.921\n",
      "Epoch 15/25 | Train: 0.0005 | Val: 0.0223 | R²: 0.902\n",
      "Epoch 16/25 | Train: 0.0045 | Val: 0.0218 | R²: 0.904\n",
      "Epoch 17/25 | Train: 0.0004 | Val: 0.0248 | R²: 0.891\n",
      "Epoch 18/25 | Train: 0.0144 | Val: 0.0260 | R²: 0.886\n",
      "Epoch 19/25 | Train: 0.0010 | Val: 0.0255 | R²: 0.888\n",
      "Epoch 20/25 | Train: 0.0005 | Val: 0.0218 | R²: 0.904\n",
      "Epoch 21/25 | Train: 0.0039 | Val: 0.0244 | R²: 0.893\n",
      "Epoch 22/25 | Train: 0.0009 | Val: 0.0242 | R²: 0.894\n",
      "Epoch 23/25 | Train: 0.0052 | Val: 0.0273 | R²: 0.880\n",
      "Epoch 24/25 | Train: 0.0082 | Val: 0.0318 | R²: 0.861\n",
      "Epoch 25/25 | Train: 0.0006 | Val: 0.0234 | R²: 0.897\n",
      "\n",
      "Best model was at epoch 8 with val loss 0.0132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            all_preds.extend(outputs.cpu().numpy().flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    avg_train = train_loss / len(train_loader)\n",
    "    avg_val = val_loss / len(val_loader)\n",
    "    r2 = r2_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d}/25 | Train: {avg_train:.4f} | Val: {avg_val:.4f} | R²: {r2:.3f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val < best_val_loss:\n",
    "        best_val_loss = avg_val\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), 'models/resnet18_best.pth')\n",
    "        print(f\"  → Best model saved (epoch {best_epoch})\")\n",
    "\n",
    "print(f\"\\nBest model was at epoch {best_epoch} with val loss {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c7db2-39cc-4235-b586-da224b639dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
